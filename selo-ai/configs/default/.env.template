# SELO AI Default Configuration
# Optimized for systems with 24GB+ RAM and dedicated GPU
# Copy to backend/.env and adjust values as needed for your environment.

# Async SQLAlchemy URL for PostgreSQL (local default)
# Format: postgresql+asyncpg://USER:PASS@HOST/DBNAME
DATABASE_URL=postgresql+asyncpg://seloai:password@localhost/seloai

# API key for securing endpoints (change in production)
SELO_SYSTEM_API_KEY=dev-secret-key-change-me

# Ollama configuration
OLLAMA_BASE_URL=http://127.0.0.1:11434

# Brave Search API Key (optional but recommended for web search functionality)
# Get your free API key at: https://brave.com/search/api/

# Default Model Selection
CONVERSATIONAL_MODEL=llama3:8b
ANALYTICAL_MODEL=qwen2.5:3b
REFLECTION_LLM=qwen2.5:3b
EMBEDDING_MODEL=nomic-embed-text

# Backend server settings
HOST=0.0.0.0
PORT=8000

# CORS for the frontend URL
CORS_ORIGINS=http://localhost:3000

# === Reflection-first and generation budgets ===
REFLECTION_ENFORCE_NO_TIMEOUTS=true
REFLECTION_SYNC_MODE=sync
REFLECTION_LLM_TIMEOUT_S=0
REFLECTION_SYNC_TIMEOUT_S=0
LLM_TIMEOUT=0
REFLECTION_REQUIRED=true

# Token budgets (tier-aware: installers detect GPU and set optimal values)
# Unbounded prompt-constrained generation by default; installers can override.
CHAT_NUM_PREDICT=0
CHAT_TEMPERATURE=0.6
CHAT_TOP_K=40
CHAT_TOP_P=0.9
CHAT_NUM_CTX=8192                    # qwen2.5:3b native capacity (was 4096)
REFLECTION_NUM_PREDICT=0
REFLECTION_MAX_TOKENS=0
REFLECTION_WORD_MIN=170              # Minimum word count (all tiers)
REFLECTION_WORD_MAX=500              # Standard tier (High tier: 650)
REFLECTION_TEMPERATURE=0.35
REFLECTION_OUTPUT_STYLE=verbose
REFLECTION_IDENTITY_MAX_RETRIES=4
ANALYTICAL_NUM_PREDICT=640           # Standard tier (High tier: 1536)
ANALYTICAL_TEMPERATURE=0.2

# === GPU/CUDA Configuration ===
CUDA_VISIBLE_DEVICES=0
CUDA_DEVICE_ORDER=PCI_BUS_ID
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:256,expandable_segments:True
TORCH_CUDA_MEMORY_FRACTION=0.7
CUDA_LAUNCH_BLOCKING=0

# Model runtime optimizations
OLLAMA_KEEP_ALIVE=15m
OLLAMA_NUM_PARALLEL=1
OLLAMA_MAX_LOADED_MODELS=2
